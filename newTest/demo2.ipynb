{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from pymongo import MongoClient\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to MongoDB database 'PDFData_sample', collection 'DynamicDimensionsNew'\n",
      "Formatted data successfully saved to output_formatted.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Function to extract dimensions and sizes dynamically from the PDF\n",
    "def extract_dimensions_with_sizes(pdf_path):\n",
    "    dimensions = []\n",
    "    headers = []  # To store the main and sub-headers dynamically\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                if len(table) > 0:\n",
    "                    # Extract the headers (first row) and data rows\n",
    "                    current_headers = table[0]\n",
    "                    if not headers:  # Capture headers only once\n",
    "                        headers = current_headers\n",
    "                    for row in table[1:]:\n",
    "                        if len(row) == len(headers):  # Ensure valid row\n",
    "                            row_data = dict(zip(headers, row))\n",
    "                            dimensions.append(row_data)\n",
    "    return dimensions, headers\n",
    "\n",
    "# Function to process and structure extracted data\n",
    "def process_dimensions(dimensions, headers):\n",
    "    processed_data = []\n",
    "\n",
    "    for record in dimensions:\n",
    "        processed_record = {}\n",
    "        for header, value in record.items():\n",
    "            if header and header.strip():\n",
    "                processed_record[header.strip()] = value\n",
    "        processed_data.append(processed_record)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    return df\n",
    "\n",
    "# Function to save DataFrame to MongoDB\n",
    "def save_to_mongodb(df, db_name, collection_name):\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Convert DataFrame to dictionary records and insert into MongoDB\n",
    "    records = df.to_dict(orient='records')\n",
    "    collection.insert_many(records)\n",
    "    print(f\"Data saved to MongoDB database '{db_name}', collection '{collection_name}'\")\n",
    "\n",
    "# Function to save DataFrame to Excel with formatting\n",
    "def save_to_excel_formatted(df, output_file):\n",
    "    with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"Sheet1\")\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "        # Set column widths for better readability\n",
    "        for i, col in enumerate(df.columns):\n",
    "            column_width = max(df[col].astype(str).map(len).max(), len(col))\n",
    "            worksheet.set_column(i, i, column_width)\n",
    "\n",
    "    print(f\"Formatted data successfully saved to {output_file}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    pdf_path = r\"E:\\git\\Automated-Email-Parsing-and-Document-Generation\\input_doc.pdf\"  # Replace with your PDF file path\n",
    "    output_excel_path = \"output_formatted.xlsx\"  # Replace with your desired output Excel file path\n",
    "    db_name = \"PDFData_sample\"\n",
    "    collection_name = \"DynamicDimensionsNew\"\n",
    "\n",
    "    # Extract dimensions dynamically\n",
    "    dimensions, headers = extract_dimensions_with_sizes(pdf_path)\n",
    "\n",
    "    # Process and structure dimensions\n",
    "    dataframe = process_dimensions(dimensions, headers)\n",
    "\n",
    "    # Save to MongoDB\n",
    "    save_to_mongodb(dataframe, db_name, collection_name)\n",
    "\n",
    "    # Save to Excel with formatting\n",
    "    save_to_excel_formatted(dataframe, output_excel_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 records saved to MongoDB collection 'spec_sheet'.\n",
      "Spec Sheet data successfully saved to spec_sheet_output.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7040\\3222115890.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, grand_total])\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import random\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Update with your MongoDB URI\n",
    "\n",
    "db = client[\"PDFData_sample\"]\n",
    "collection = db[\"spec_sheet\"]\n",
    "\n",
    "def extract_spec_sheet_data(pdf_path):\n",
    "    spec_sheet_data = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_number, page in enumerate(pdf.pages, start=1):\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                # Identify the Spec Sheet table\n",
    "                if \"Spec Sheet:\" in page.extract_text():\n",
    "                    headers = table[0]  # First row is assumed to be headers\n",
    "                    cleaned_headers = [str(header).strip() if header else f\"Column_{i}\" for i, header in enumerate(headers)]\n",
    "\n",
    "                    for row in table[1:]:\n",
    "                        if len(row) == len(cleaned_headers):\n",
    "                            # Create a clean row dictionary with valid string keys\n",
    "                            row_data = dict(zip(cleaned_headers, row))\n",
    "                            spec_sheet_data.append(row_data)\n",
    "    return spec_sheet_data\n",
    "\n",
    "def save_spec_sheet_to_mongo(data):\n",
    "    if data:\n",
    "        collection.insert_many(data)\n",
    "        print(f\"{len(data)} records saved to MongoDB collection 'spec_sheet'.\")\n",
    "    else:\n",
    "        print(\"No data to save to MongoDB.\")\n",
    "\n",
    "def save_to_excel(df, output_file):\n",
    "    # Remove the '_id' column if it exists\n",
    "    if '_id' in df.columns:\n",
    "        df = df.drop(columns=['_id'])\n",
    "\n",
    "    # Move the 'Qty' column to the end if it exists\n",
    "    if 'Qty' in df.columns:\n",
    "        qty_column = df.pop('Qty')\n",
    "        df['Qty'] = qty_column\n",
    "\n",
    "        # Convert 'Qty' to numeric, handling errors\n",
    "        df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce')\n",
    "\n",
    "        # Add 'perrate' and 'total' columns\n",
    "        df['perrate'] = [round(random.uniform(0.2, 0.8), 2) for _ in range(len(df))]  # Assign random values in range 0.2 to 0.8 with 2 decimals\n",
    "        df['total'] = df['Qty'] * df['perrate']\n",
    "\n",
    "        # Add a final row for the grand total\n",
    "        grand_total = pd.DataFrame({\n",
    "            'Qty': [None],\n",
    "            'perrate': [None],\n",
    "            'total': [df['total'].sum()]\n",
    "        })\n",
    "        grand_total.index = ['Grand Total']\n",
    "        df = pd.concat([df, grand_total])\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Spec Sheet data successfully saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"input_doc.pdf\"  # Replace with your PDF path\n",
    "\n",
    "    # Extract Spec Sheet data\n",
    "    spec_sheet_data = extract_spec_sheet_data(pdf_path)\n",
    "\n",
    "    # Save to MongoDB\n",
    "    save_spec_sheet_to_mongo(spec_sheet_data)\n",
    "\n",
    "    # Save to Excel\n",
    "    if spec_sheet_data:\n",
    "        df = pd.DataFrame(spec_sheet_data)\n",
    "        output_file = \"spec_sheet_output.xlsx\"\n",
    "        save_to_excel(df, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
