{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "from pymongo import MongoClient\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to MongoDB database 'PDFData_sample', collection 'DynamicDimensionsNew'\n",
      "Formatted data successfully saved to output_formatted.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Function to extract dimensions and sizes dynamically from the PDF\n",
    "def extract_dimensions_with_sizes(pdf_path):\n",
    "    dimensions = []\n",
    "    headers = []  # To store the main and sub-headers dynamically\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                if len(table) > 0:\n",
    "                    # Extract the headers (first row) and data rows\n",
    "                    current_headers = table[0]\n",
    "                    if not headers:  # Capture headers only once\n",
    "                        headers = current_headers\n",
    "                    for row in table[1:]:\n",
    "                        if len(row) == len(headers):  # Ensure valid row\n",
    "                            row_data = dict(zip(headers, row))\n",
    "                            dimensions.append(row_data)\n",
    "    return dimensions, headers\n",
    "\n",
    "# Function to process and structure extracted data\n",
    "def process_dimensions(dimensions, headers):\n",
    "    processed_data = []\n",
    "\n",
    "    for record in dimensions:\n",
    "        processed_record = {}\n",
    "        for header, value in record.items():\n",
    "            if header and header.strip():\n",
    "                processed_record[header.strip()] = value\n",
    "        processed_data.append(processed_record)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    return df\n",
    "\n",
    "# Function to save DataFrame to MongoDB\n",
    "def save_to_mongodb(df, db_name, collection_name):\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Convert DataFrame to dictionary records and insert into MongoDB\n",
    "    records = df.to_dict(orient='records')\n",
    "    collection.insert_many(records)\n",
    "    print(f\"Data saved to MongoDB database '{db_name}', collection '{collection_name}'\")\n",
    "\n",
    "# Function to save DataFrame to Excel with formatting\n",
    "def save_to_excel_formatted(df, output_file):\n",
    "    with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"Sheet1\")\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "        # Set column widths for better readability\n",
    "        for i, col in enumerate(df.columns):\n",
    "            column_width = max(df[col].astype(str).map(len).max(), len(col))\n",
    "            worksheet.set_column(i, i, column_width)\n",
    "\n",
    "    print(f\"Formatted data successfully saved to {output_file}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    pdf_path = r\"E:\\git\\Automated-Email-Parsing-and-Document-Generation\\input_doc.pdf\"  # Replace with your PDF file path\n",
    "    output_excel_path = \"output_formatted.xlsx\"  # Replace with your desired output Excel file path\n",
    "    db_name = \"PDFData_sample\"\n",
    "    collection_name = \"DynamicDimensionsNew\"\n",
    "\n",
    "    # Extract dimensions dynamically\n",
    "    dimensions, headers = extract_dimensions_with_sizes(pdf_path)\n",
    "\n",
    "    # Process and structure dimensions\n",
    "    dataframe = process_dimensions(dimensions, headers)\n",
    "\n",
    "    # Save to MongoDB\n",
    "    save_to_mongodb(dataframe, db_name, collection_name)\n",
    "\n",
    "    # Save to Excel with formatting\n",
    "    save_to_excel_formatted(dataframe, output_excel_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________________________VERSION 2_______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to MongoDB database 'PDFData', collection 'FinalDimensions'\n",
      "Formatted data successfully saved to outputFinal.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Function to extract dimensions and sizes dynamically from the PDF\n",
    "def extract_dimensions_with_sizes(pdf_path):\n",
    "    dimensions = []\n",
    "    headers = []  # To store the main and sub-headers dynamically\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                if len(table) > 0:\n",
    "                    # Extract the headers (first row) and data rows\n",
    "                    current_headers = table[0]\n",
    "                    if not headers:  # Capture headers only once\n",
    "                        headers = current_headers\n",
    "                    for row in table[1:]:\n",
    "                        if len(row) == len(headers):  # Ensure valid row\n",
    "                            row_data = dict(zip(headers, row))\n",
    "                            dimensions.append(row_data)\n",
    "    return dimensions, headers\n",
    "\n",
    "# Function to process and structure extracted data\n",
    "def process_dimensions(dimensions, headers):\n",
    "    processed_data = []\n",
    "\n",
    "    for record in dimensions:\n",
    "        processed_record = {}\n",
    "        for header, value in record.items():\n",
    "            if header and header.strip():\n",
    "                processed_record[header.strip()] = value\n",
    "        processed_data.append(processed_record)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    return df\n",
    "\n",
    "# Function to save DataFrame to MongoDB\n",
    "def save_to_mongodb(df, db_name, collection_name):\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Convert DataFrame to dictionary records and insert into MongoDB\n",
    "    records = df.to_dict(orient='records')\n",
    "    collection.insert_many(records)\n",
    "    print(f\"Data saved to MongoDB database '{db_name}', collection '{collection_name}'\")\n",
    "\n",
    "# Function to save DataFrame to Excel with formatting\n",
    "def save_to_excel_formatted(df, output_file):\n",
    "    with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"Sheet1\")\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "        # Set column widths for better readability\n",
    "        for i, col in enumerate(df.columns):\n",
    "            column_width = max(df[col].astype(str).map(len).max(), len(col))\n",
    "            worksheet.set_column(i, i, column_width)\n",
    "\n",
    "    print(f\"Formatted data successfully saved to {output_file}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    pdf_path = \"input_doc.pdf\"  # Replace with your PDF file path\n",
    "    output_excel_path = \"output_formatted.xlsx\"  # Replace with your desired output Excel file path\n",
    "    db_name = \"newPDFData\"\n",
    "    collection_name = \"DynamicDimensions\"\n",
    "\n",
    "    # Extract dimensions dynamically\n",
    "    dimensions, headers = extract_dimensions_with_sizes(pdf_path)\n",
    "\n",
    "    # Process and structure dimensions\n",
    "    dataframe = process_dimensions(dimensions, headers)\n",
    "\n",
    "    # Save to MongoDB\n",
    "    save_to_mongodb(dataframe, db_name, collection_name)\n",
    "\n",
    "    # Save to Excel with formatting\n",
    "    save_to_excel_formatted(dataframe, output_excel_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------VERSION 3------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Headers: ['Dim', 'Description', 'Comment', 'Tol\\n(-)', 'Tol\\n(+)', 'XS', None, None, 'S', None, None]\n",
      "Row mismatch with headers: ['Incremen\\nt', 'Sampl\\ne', 'Deviatio\\nn', 'Incremen\\nt', 'Sampl\\ne', 'Deviatio\\nn', 'Incremen\\nt', 'Sampl\\ne', 'Deviatio\\nn']\n",
      "Row mismatch with headers: ['54.00', '', '', '58.00', '', '', '64.00', '', '']\n",
      "Row mismatch with headers: ['40.00', '', '', '42.00', '', '', '44.00', '', '']\n",
      "Row mismatch with headers: ['2.50', '', '', '2.50', '', '', '2.50', '', '']\n",
      "Row mismatch with headers: ['41.00', '', '', '43.00', '', '', '45.00', '', '']\n",
      "Row mismatch with headers: ['22.80', '', '', '23.60', '', '', '24.40', '', '']\n",
      "Row mismatch with headers: ['19.25', '', '', '20.50', '', '', '21.75', '', '']\n",
      "Row mismatch with headers: ['17.25', '', '', '18.50', '', '', '20.50', '', '']\n",
      "Row mismatch with headers: ['17.80', '', '', '18.60', '', '', '19.40', '', '']\n",
      "Row mismatch with headers: ['Displaying 1-9 results', None, None, None, None, None, None, None, None]\n",
      "Row mismatch with headers: ['9.90', '', '', '10.30', '', '', '10.70', '', '']\n",
      "Row mismatch with headers: ['2.00', '', '', '2.00', '', '', '2.00', '', '']\n",
      "Row mismatch with headers: ['37.00', '', '', '39.00', '', '', '41.50', '', '']\n",
      "Row mismatch with headers: ['38.00', '', '', '40.00', '', '', '42.50', '', '']\n",
      "Row mismatch with headers: ['64.00', '', '', '66.00', '', '', '69.00', '', '']\n",
      "Row mismatch with headers: ['2.00', '', '', '2.00', '', '', '2.00', '', '']\n",
      "Row mismatch with headers: ['Displaying 10-15 results', None, None, None, None, None, None, None, None]\n",
      "Row mismatch with headers: ['Main Fabric', '3', '100% Organic in-conversion cottonCombed']\n",
      "Row mismatch with headers: ['Rib', '2', '']\n",
      "Row mismatch with headers: ['Finish/Treatment', '1', '']\n",
      "Row mismatch with headers: ['Thread', '2', '']\n",
      "Row mismatch with headers: ['Main Label', '1', '100% RecycledPolyester']\n",
      "Row mismatch with headers: ['SizeLabel', '2', '100% RecycledPolyester']\n",
      "Row mismatch with headers: ['CareLabel', '1', '100% RecycledPolyester']\n",
      "Row mismatch with headers: ['HangTag', '1', '100% Nylon']\n",
      "Data saved to MongoDB database 'newPDFData', collection 'DynamicDimensions'\n",
      "Formatted data successfully saved to output_formatted.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Function to extract dimensions and sizes dynamically from the PDF\n",
    "def extract_dimensions_with_sizes(pdf_path):\n",
    "    dimensions = []\n",
    "    headers = []  # To store the main and sub-headers dynamically\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                if len(table) > 0:\n",
    "                    # Extract the headers (first row) and data rows\n",
    "                    current_headers = table[0]\n",
    "                    if not headers:  # Capture headers only once\n",
    "                        headers = current_headers\n",
    "                        print(f\"Extracted Headers: {headers}\")  # Debugging headers\n",
    "                    for row in table[1:]:\n",
    "                        if len(row) == len(headers):  # Ensure valid row\n",
    "                            row_data = dict(zip(headers, row))\n",
    "                            dimensions.append(row_data)\n",
    "                        else:\n",
    "                            print(f\"Row mismatch with headers: {row}\")  # Debugging row mismatches\n",
    "    return dimensions, headers\n",
    "\n",
    "# Function to process and structure extracted data\n",
    "def process_dimensions(dimensions, headers):\n",
    "    processed_data = []\n",
    "\n",
    "    # Ensure all required columns are present\n",
    "    required_columns = [\"Dim\", \"Description\", \"Tol (-)\", \"Tol (+)\", \"XS\", \"S\", \"M\", \"L\", \"XL\"]\n",
    "    headers = [header.strip() if header else \"\" for header in headers]\n",
    "    for col in required_columns:\n",
    "        if col not in headers:\n",
    "            headers.append(col)  # Add missing columns\n",
    "\n",
    "    for record in dimensions:\n",
    "        processed_record = {}\n",
    "        for header, value in record.items():\n",
    "            if header and header.strip():\n",
    "                processed_record[header.strip()] = value\n",
    "\n",
    "        # Add missing columns with default values\n",
    "        for col in required_columns:\n",
    "            if col not in processed_record:\n",
    "                processed_record[col] = \"N/A\"\n",
    "\n",
    "        processed_data.append(processed_record)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(processed_data, columns=required_columns)\n",
    "    return df\n",
    "\n",
    "# Function to save DataFrame to MongoDB\n",
    "def save_to_mongodb(df, db_name, collection_name):\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Convert DataFrame to dictionary records and insert into MongoDB\n",
    "    records = df.to_dict(orient='records')\n",
    "    collection.insert_many(records)\n",
    "    print(f\"Data saved to MongoDB database '{db_name}', collection '{collection_name}'\")\n",
    "\n",
    "# Function to save DataFrame to Excel with formatting\n",
    "def save_to_excel_formatted(df, output_file):\n",
    "    with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"Sheet1\")\n",
    "        worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "        # Set column widths for better readability\n",
    "        for i, col in enumerate(df.columns):\n",
    "            column_width = max(df[col].astype(str).map(len).max(), len(col))\n",
    "            worksheet.set_column(i, i, column_width)\n",
    "\n",
    "    print(f\"Formatted data successfully saved to {output_file}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    pdf_path = \"input_doc.pdf\"  # Replace with your PDF file path\n",
    "    output_excel_path = \"output_formatted.xlsx\"  # Replace with your desired output Excel file path\n",
    "    db_name = \"newPDFData\"\n",
    "    collection_name = \"DynamicDimensions\"\n",
    "\n",
    "    # Extract dimensions dynamically\n",
    "    dimensions, headers = extract_dimensions_with_sizes(pdf_path)\n",
    "\n",
    "    # Process and structure dimensions\n",
    "    dataframe = process_dimensions(dimensions, headers)\n",
    "\n",
    "    # Save to MongoDB\n",
    "    save_to_mongodb(dataframe, db_name, collection_name)\n",
    "\n",
    "    # Save to Excel with formatting\n",
    "    save_to_excel_formatted(dataframe, output_excel_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to mongo_output_cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Update with your MongoDB URI\n",
    "\n",
    "db = client[\"pdf_data\"]\n",
    "collection = db[\"dimensions\"]\n",
    "\n",
    "def extract_and_store_in_mongo(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                if len(table) > 0:\n",
    "                    headers = table[0]  # First row is assumed to be headers\n",
    "                    cleaned_headers = [str(header).strip() if header else f\"Column_{i}\" for i, header in enumerate(headers)]\n",
    "\n",
    "                    for row in table[1:]:\n",
    "                        if len(row) == len(cleaned_headers):\n",
    "                            # Create a clean row dictionary with valid string keys\n",
    "                            row_data = dict(zip(cleaned_headers, row))\n",
    "                            collection.insert_one(row_data)  # Insert row into MongoDB\n",
    "\n",
    "def process_data_from_mongo():\n",
    "    # Query MongoDB for all columns and process rows dynamically\n",
    "    records = collection.find()\n",
    "    data = []\n",
    "    for record in records:\n",
    "        # Convert MongoDB record to dictionary and remove irrelevant fields\n",
    "        cleaned_record = {k: v for k, v in record.items() if k != \"_id\" and v not in (None, \"\", \"N/A\")}\n",
    "        data.append(cleaned_record)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Remove empty columns\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # Limit rows to 2-10 dynamically (assuming 1-based indexing in the table)\n",
    "    if len(df) > 10:\n",
    "        df = df.iloc[1:10]\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_to_excel(df, output_file):\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Data successfully saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"input_doc.pdf\"  # Replace with your PDF path\n",
    "    extract_and_store_in_mongo(pdf_path)\n",
    "\n",
    "    # Process data from MongoDB\n",
    "    processed_df = process_data_from_mongo()\n",
    "\n",
    "    # Save to Excel\n",
    "    output_file = \"mongo_output_cleaned.xlsx\"\n",
    "    save_to_excel(processed_df, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
